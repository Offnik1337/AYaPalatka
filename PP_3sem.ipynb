{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNG1D9vKAFiHuubwudhyp9z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Offnik1337/AYaPalatka/blob/master/PP_3sem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скачивание модели"
      ],
      "metadata": {
        "id": "Shku_BDJ5VYl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4ugWPu8zrRS"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade gdown\n",
        "import gdown\n",
        "\n",
        "szModelID = \"1sawKZB-can8hUqlmrcC0w4UwLsGD_Orz\"\n",
        "\n",
        "gdown.download_folder(id=szModelID)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DqKqneEm5tGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from skimage import measure\n",
        "from skimage.io import imread, imsave\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import dilation, disk\n",
        "from skimage.draw import polygon_perimeter\n",
        "CLASSES = 2\n",
        "COLORS = ['red','black']\n",
        "SAMPLE_SIZE = (256, 256)\n",
        "OUTPUT_SIZE = (1080, 1920)\n",
        "\n",
        "#Инициализация модели\n",
        "def getmodel():\n",
        "  def downsample_block(filters, size, batch_norm=True):\n",
        "      initializer = tf.keras.initializers.GlorotNormal()\n",
        "      result = tf.keras.Sequential()\n",
        "      result.add(\n",
        "        tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                              kernel_initializer=initializer, use_bias=False))\n",
        "      if batch_norm:\n",
        "          result.add(tf.keras.layers.BatchNormalization())\n",
        "      result.add(tf.keras.layers.LeakyReLU())\n",
        "      return result\n",
        "\n",
        "  def upsample_block(filters, size, dropout=False):\n",
        "      initializer = tf.keras.initializers.GlorotNormal()\n",
        "      result = tf.keras.Sequential()\n",
        "      result.add(\n",
        "          tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
        "                                          kernel_initializer=initializer, use_bias=False))\n",
        "      result.add(tf.keras.layers.BatchNormalization())\n",
        "      if dropout:\n",
        "          result.add(tf.keras.layers.Dropout(0.25))\n",
        "      result.add(tf.keras.layers.ReLU())\n",
        "      return result\n",
        "\n",
        "  def output_layer(size):\n",
        "      initializer = tf.keras.initializers.GlorotNormal()\n",
        "      return tf.keras.layers.Conv2DTranspose(CLASSES, size, strides=2, padding='same',\n",
        "                                            kernel_initializer=initializer, activation='sigmoid')\n",
        "\n",
        "\n",
        "  inp_layer = tf.keras.layers.Input(shape=SAMPLE_SIZE + (3,))\n",
        "  downsample_stack = [\n",
        "      downsample_block(64, 4, batch_norm=False),\n",
        "      downsample_block(128, 4),\n",
        "      downsample_block(256, 4),\n",
        "      downsample_block(512, 4),\n",
        "      downsample_block(512, 4),\n",
        "      downsample_block(512, 4),\n",
        "      downsample_block(512, 4),\n",
        "  ]\n",
        "\n",
        "  upsample_stack = [\n",
        "      upsample_block(512, 4, dropout=True),\n",
        "      upsample_block(512, 4, dropout=True),\n",
        "      upsample_block(512, 4, dropout=True),\n",
        "      upsample_block(256, 4),\n",
        "      upsample_block(128, 4),\n",
        "      upsample_block(64, 4)\n",
        "  ]\n",
        "\n",
        "  out_layer = output_layer(4)\n",
        "\n",
        "  # Реализуем skip connections\n",
        "  x = inp_layer\n",
        "\n",
        "  downsample_skips = []\n",
        "\n",
        "  for block in downsample_stack:\n",
        "      x = block(x)\n",
        "      downsample_skips.append(x)\n",
        "      \n",
        "  downsample_skips = reversed(downsample_skips[:-1])\n",
        "\n",
        "  for up_block, down_block in zip(upsample_stack, downsample_skips):\n",
        "      x = up_block(x)\n",
        "      x = tf.keras.layers.Concatenate()([x, down_block])\n",
        "\n",
        "  out_layer = out_layer(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs=inp_layer, outputs=out_layer)\n",
        "\n",
        "  def dice_mc_metric(a, b):\n",
        "      a = tf.unstack(a, axis=3)\n",
        "      b = tf.unstack(b, axis=3)\n",
        "      \n",
        "      dice_summ = 0\n",
        "      \n",
        "      for i, (aa, bb) in enumerate(zip(a, b)):\n",
        "          numenator = 2 * tf.math.reduce_sum(aa * bb) + 1\n",
        "          denomerator = tf.math.reduce_sum(aa + bb) + 1\n",
        "          dice_summ += numenator / denomerator\n",
        "          \n",
        "      avg_dice = dice_summ / CLASSES\n",
        "      \n",
        "      return avg_dice\n",
        "\n",
        "  def dice_mc_loss(a, b):\n",
        "      return 1 - dice_mc_metric(a, b)\n",
        "\n",
        "  def dice_bce_mc_loss(a, b):\n",
        "      return 0.3 * dice_mc_loss(a, b) + tf.keras.losses.binary_crossentropy(a, b)\n",
        "\n",
        "  model.compile(optimizer='adam', loss=[dice_bce_mc_loss], metrics=[dice_mc_metric])\n",
        "  return model\n",
        "\n",
        "def work(szSrcdir, szDstdir):\n",
        "  pics = glob.glob(szSrcdir + \"/*.*\")\n",
        "  if not os.path.exists(szDstdir):\n",
        "    os.mkdir(szDstdir)\n",
        "  model = getmodel()\n",
        "  model.load_weights(\"modely/unet_like\")\n",
        "  rgb_colors = [(0,   0,   0),(255, 0,   0)]\n",
        "  for filename in pics:\n",
        "      print(filename)\n",
        "      frame = imread(filename)\n",
        "      if frame.shape[2] == 4:\n",
        "        frame = frame[:,:,:3]\n",
        "      sample = tfa.image.gaussian_filter2d(frame)\n",
        "      sample = resize(sample, SAMPLE_SIZE)\n",
        "      predict = model.predict(sample.reshape((1,) +  SAMPLE_SIZE + (3,)))\n",
        "      predict = predict.reshape(SAMPLE_SIZE + (CLASSES,)) \n",
        "      scale = frame.shape[0] / SAMPLE_SIZE[0], frame.shape[1] / SAMPLE_SIZE[1]\n",
        "      frame = (frame / 1.5).astype(np.uint8)\n",
        "      for channel in range(1, CLASSES): \n",
        "          contour_overlay = np.zeros((frame.shape[0], frame.shape[1]))\n",
        "          contours = measure.find_contours(np.array(predict[:,:,channel]))\n",
        "          try:\n",
        "              for contour in contours:\n",
        "                  rr, cc = polygon_perimeter(contour[:, 0] * scale[0],\n",
        "                                            contour[:, 1] * scale[1],\n",
        "                                            shape=contour_overlay.shape)\n",
        "                  contour_overlay[rr, cc] = 1\n",
        "              contour_overlay = dilation(contour_overlay, disk(1))\n",
        "              frame[contour_overlay == 1] = rgb_colors[channel]\n",
        "          except:\n",
        "              pass\n",
        "      imsave(f'{szDstdir}/{os.path.basename(filename)}', frame)\n",
        "  print(\"Done\")\n",
        "\n",
        "\n",
        "szSrc = input(\"Введите путь к файлам с картинками для обработки \")\n",
        "szDst = input(\"Введите путь назначения обработанных фото \")\n",
        "work(szSrc, szDst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "o0XSbThQ5fJS",
        "outputId": "f444a12b-c214-4587-8c4d-d9ed0cb569d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.8/dist-packages (0.19.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Введите путь к файлам с картинками для обработки src\n",
            "Введите путь назначения обработанных фото dst\n",
            "src/69.png\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d1708bbd49d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0mszSrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Введите путь к файлам с картинками для обработки \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0mszDst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Введите путь назначения обработанных фото \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m \u001b[0mwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mszSrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mszDst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-d1708bbd49d8>\u001b[0m in \u001b[0;36mwork\u001b[0;34m(szSrcdir, szDstdir)\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m       \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_filter2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    }
  ]
}